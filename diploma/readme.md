# –ó–∞–¥–∞–Ω–∏–µ –Ω–∞ –¥–∏–ø–ª–æ–º–Ω—É—é —Ä–∞–±–æ—Ç—É

## –¢–µ–º–∞: "–î–∞—à–±–æ—Ä–¥ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–æ–≤"

### –¶–µ–ª—å –ø—Ä–æ–µ–∫—Ç–∞

–†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π ETL-pipeline –Ω–∞ –±–∞–∑–µ Apache Airflow –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–±–æ—Ä–∞, –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–æ–≤. –°–∏—Å—Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ (–≤ 9:00) —Å–æ–±–∏—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∏—Ö –∏ –∑–∞–≥—Ä—É–∂–∞—Ç—å –≤ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫—É—é –ë–î –∏ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–∞–Ω–Ω—ã—Ö (Data Warehouse) –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–∞ –¥–∞—à–±–æ—Ä–¥–µ.

## –ö–ª—é—á–µ–≤—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

### 1. Data Warehouse —Å SCD Type 2

–•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–∞–Ω–Ω—ã—Ö (Data Warehouse) –¥–æ–ª–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é **Slowly Changing Dimensions (SCD) Type 2** –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö –∏–∑–º–µ—Ä–µ–Ω–∏–π (dimensions). –≠—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –ø–æ–ª–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –∏–∑–º–µ–Ω–µ–Ω–∏–π –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∏—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è.

**–ß—Ç–æ —Ç–∞–∫–æ–µ SCD Type 2?**

**SCD Type 2** - —ç—Ç–æ –º–µ—Ç–æ–¥ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –∏–∑–º–µ—Ä–µ–Ω–∏—è—Ö, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º:

- –ü—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∞—Ç—Ä–∏–±—É—Ç–∞ —Å–æ–∑–¥–∞–µ—Ç—Å—è –ù–û–í–ê–Ø –≤–µ—Ä—Å–∏—è –∑–∞–ø–∏—Å–∏
- –°—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –∏ –ø–æ–º–µ—á–∞–µ—Ç—Å—è –∫–∞–∫ –Ω–µ–∞–∫—Ç—É–∞–ª—å–Ω–∞—è
- –ö–∞–∂–¥–∞—è –≤–µ—Ä—Å–∏—è –∏–º–µ–µ—Ç –ø–µ—Ä–∏–æ–¥ –¥–µ–π—Å—Ç–≤–∏—è (effective_date, expiration_date)
- –¢–µ–∫—É—â–∞—è –≤–µ—Ä—Å–∏—è –∏–º–µ–µ—Ç —Ñ–ª–∞–≥ is_current = TRUE

**–ü—Ä–∏–º–µ—Ä:**

```text
–ö–ª–∏–µ–Ω—Ç –ø–µ—Ä–µ–µ—Ö–∞–ª –∏–∑ –ú–æ—Å–∫–≤—ã –≤ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥ 15.06.2025

–î–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è:
customer_key | customer_id | city   | effective_date | expiration_date | is_current
1001         | 123         | –ú–æ—Å–∫–≤–∞ | 2025-01-01     | 9999-12-31      | TRUE

–ü–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è:
customer_key | customer_id | city             | effective_date | expiration_date | is_current
1001         | 123         | –ú–æ—Å–∫–≤–∞           | 2025-01-01     | 2025-06-14      | FALSE  ‚Üê –∑–∞–∫—Ä—ã—Ç–∞
1125         | 123         | –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥  | 2025-06-15     | 9999-12-31      | TRUE   ‚Üê –Ω–æ–≤–∞—è
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**

- –ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π
- –ê–Ω–∞–ª–∏–∑ "–∫–∞–∫ –±—ã–ª–æ" –Ω–∞ –ª—é–±—É—é –¥–∞—Ç—É
- –¢–æ—á–Ω–æ—Å—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –æ—Ç—á–µ—Ç–æ–≤
- –ê—É–¥–∏—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π

### 2. –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π

**–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π**: –í—Å–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –¥–∞–Ω–Ω—ã—Ö –¥–æ–ª–∂–Ω—ã –æ—Å—É—â–µ—Å—Ç–≤–ª—è—Ç—å—Å—è —á–µ—Ä–µ–∑ **Airflow Connections**, –∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–ª–æ–≥–∏–Ω—ã, –ø–∞—Ä–æ–ª–∏, —Ç–æ–∫–µ–Ω—ã) –¥–æ–ª–∂–Ω—ã –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å—Å—è —á–µ—Ä–µ–∑ **–ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (.env —Ñ–∞–π–ª)**. –ñ–µ—Å—Ç–∫–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –∫–æ–¥–µ –∑–∞–ø—Ä–µ—â–µ–Ω–æ.

```python
# –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û - –ù–ò–ö–û–ì–î–ê –¢–ê–ö –ù–ï –î–ï–õ–ê–ô–¢–ï!
conn = psycopg2.connect(
    host='postgres',
    user='user',
    password='password123'  # –ñ–ï–°–¢–ö–ò–ô –ö–û–î –ü–ê–†–û–õ–Ø!
)

# –ü–†–ê–í–ò–õ–¨–ù–û
from airflow.providers.postgres.hooks.postgres import PostgresHook

hook = PostgresHook(postgres_conn_id='postgres_source')
conn = hook.get_conn()
```

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**

1. –í—Å–µ –ø–∞—Ä–æ–ª–∏ –≤ —Ñ–∞–π–ª–µ `.env`
2. `.env` –¥–æ–±–∞–≤–ª–µ–Ω –≤ `.gitignore`
3. –í—Å–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è —á–µ—Ä–µ–∑ Airflow Connections
4. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Hooks (PostgresHook, MongoHook –∏ —Ç.–¥.)

### 3. –ú–∏–Ω–∏–º—É–º 3 –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö

–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:

1. **PostgreSQL** - —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω–∞—è –ë–î (–∑–∞–∫–∞–∑—ã, –∫–ª–∏–µ–Ω—Ç—ã)
2. **MongoDB** - –¥–æ–∫—É–º–µ–Ω—Ç–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ë–î (–æ—Ç–∑—ã–≤—ã)
3. **CSV –∏–ª–∏ FTP** - —Ñ–∞–π–ª–æ–≤—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–ø—Ä–æ–¥—É–∫—Ç—ã, –ª–æ–≥–∏ –¥–æ—Å—Ç–∞–≤–∫–∏)
4. **REST API** - –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ (–≤–µ–±-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞)

---

## –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏

–í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–Ω—É –∏–∑ –ø—Ä–µ–¥–º–µ—Ç–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π –∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç–µ —Å–≤–æ—é:

### –í–∞—Ä–∏–∞–Ω—Ç—ã –ø—Ä–µ–¥–º–µ—Ç–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π

**A. –ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω**

- –ë–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å—ã: –∑–∞–∫–∞–∑—ã, –ø–ª–∞—Ç–µ–∂–∏, –¥–æ—Å—Ç–∞–≤–∫–∞, –æ—Ç–∑—ã–≤—ã
- –ú–µ—Ç—Ä–∏–∫–∏: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤, —Å—Ä–µ–¥–Ω–∏–π —á–µ–∫, –∫–æ–Ω–≤–µ—Ä—Å–∏—è, –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã, –≥–µ–æ–≥—Ä–∞—Ñ–∏—è

**B. –°–ª—É–∂–±–∞ –¥–æ—Å—Ç–∞–≤–∫–∏**

- –ë–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å—ã: –ø—Ä–∏–µ–º –∑–∞–∫–∞–∑–æ–≤, –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è, –¥–æ—Å—Ç–∞–≤–∫–∞
- –ú–µ—Ç—Ä–∏–∫–∏: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ—Å—Ç–∞–≤–æ–∫, –≤—Ä–µ–º—è –¥–æ—Å—Ç–∞–≤–∫–∏, –∑–∞–≥—Ä—É–∑–∫–∞ –∫—É—Ä—å–µ—Ä–æ–≤, –ø—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞

**C. –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞**

- –ë–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å—ã: —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è, –∫—É—Ä—Å—ã, –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞–Ω–∏–π, –ø–æ–¥–ø–∏—Å–∫–∏
- –ú–µ—Ç—Ä–∏–∫–∏: –∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏, –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∫—É—Ä—Å–æ–≤, –≤—ã—Ä—É—á–∫–∞, –æ—Ü–µ–Ω–∫–∏ –∫—É—Ä—Å–æ–≤

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è**: –û–ø–∏—à–∏—Ç–µ –≤—ã–±—Ä–∞–Ω–Ω—É—é –æ–±–ª–∞—Å—Ç—å, –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å—ã, –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ –æ–±–æ—Å–Ω—É–π—Ç–µ –≤—ã–±–æ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö.

---

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    –ò–°–¢–û–ß–ù–ò–ö–ò –î–ê–ù–ù–´–•                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  PostgreSQL  ‚îÇ   MongoDB    ‚îÇ   CSV/FTP    ‚îÇ     REST API       ‚îÇ
‚îÇ   (orders,   ‚îÇ  (feedback)  ‚îÇ  (products,  ‚îÇ (web analytics)    ‚îÇ
‚îÇ  customers)  ‚îÇ              ‚îÇ  deliveries) ‚îÇ  [–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ]     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ              ‚îÇ              ‚îÇ                ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ           AIRFLOW DAG (–∑–∞–ø—É—Å–∫ –≤ 9:00 AM)               ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
       ‚îÇ  EXTRACT  ‚Üí  TRANSFORM  ‚Üí  LOAD                        ‚îÇ
       ‚îÇ  (–∏–∑–≤–ª–µ—á—å)  (–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å)  (–∑–∞–≥—Ä—É–∑–∏—Ç—å)               ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ               –¶–ï–õ–ï–í–´–ï –•–†–ê–ù–ò–õ–ò–©–ê                        ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
       ‚îÇ  Analytics DB        ‚îÇ    Data Warehouse               ‚îÇ
       ‚îÇ  (–∞–≥—Ä–µ–≥–∞—Ç—ã)          ‚îÇ    (–¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è + SCD Type 2)   ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ                         ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ    –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø      ‚îÇ
                    ‚îÇ  Grafana / Superset  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```text
airflow_etl_diploma_project/
‚îÇ
‚îú‚îÄ‚îÄ dags/                             # DAG-—Ñ–∞–π–ª—ã Apache Airflow
‚îÇ   ‚îú‚îÄ‚îÄ main_etl_dag.py               # –û—Å–Ω–æ–≤–Ω–æ–π ETL DAG (9:00 AM)
‚îÇ   ‚îî‚îÄ‚îÄ generate_test_data_dag.py     # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
‚îÇ
‚îú‚îÄ‚îÄ plugins/                          # –ü–ª–∞–≥–∏–Ω—ã –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã ETL
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ extractors/                   # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_extractor.py         # –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ postgres_extractor.py     # PostgreSQL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mongo_extractor.py        # MongoDB
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ csv_extractor.py          # CSV —Ñ–∞–π–ª—ã
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ftp_extractor.py          # FTP —Å–µ—Ä–≤–µ—Ä
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api_extractor.py          # REST API
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ transformers/                 # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_transformer.py       # –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_cleaner.py           # –û—á–∏—Å—Ç–∫–∞ (–¥—É–±–ª–∏–∫–∞—Ç—ã, null)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_validator.py         # –í–∞–ª–∏–¥–∞—Ü–∏—è (—Å—Ö–µ–º–∞, –¥–∏–∞–ø–∞–∑–æ–Ω—ã)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_normalizer.py        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (—Ñ–æ—Ä–º–∞—Ç—ã)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_enricher.py          # –û–±–æ–≥–∞—â–µ–Ω–∏–µ (–¥–æ–ø. –¥–∞–Ω–Ω—ã–µ)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ loaders/                      # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_loader.py            # –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analytics_loader.py       # –í –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫—É—é –ë–î
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dwh_loader.py             # –í DWH
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scd_type2_handler.py      # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ SCD Type 2
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ validators/                   # –í–∞–ª–∏–¥–∞—Ç–æ—Ä—ã
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schema_validator.py       # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–µ–º—ã
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ quality_checker.py        # –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/                        # –£—Ç–∏–ª–∏—Ç—ã
‚îÇ       ‚îú‚îÄ‚îÄ db_helpers.py
‚îÇ       ‚îú‚îÄ‚îÄ logger_config.py
‚îÇ       ‚îî‚îÄ‚îÄ constants.py
‚îÇ
‚îú‚îÄ‚îÄ init/                             # –°–∫—Ä–∏–ø—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î
‚îÇ   ‚îú‚îÄ‚îÄ init_source_db.sql            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ init_analytics_db.sql         # –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –ë–î
‚îÇ   ‚îú‚îÄ‚îÄ init_dwh.sql                  # Data Warehouse (—Å SCD Type 2)
‚îÇ   ‚îî‚îÄ‚îÄ create_views.sql              # –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤
‚îÇ
‚îú‚îÄ‚îÄ scripts/                          # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ setup_connections.py          # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Airflow Connections
‚îÇ   ‚îú‚îÄ‚îÄ generate_sample_data.py       # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îî‚îÄ‚îÄ check_data_quality.py         # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
‚îÇ
‚îú‚îÄ‚îÄ data/                             # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îú‚îÄ‚îÄ csv/                          # CSV —Ñ–∞–π–ª—ã
‚îÇ   ‚îú‚îÄ‚îÄ ftp/                          # FTP —Ñ–∞–π–ª—ã
‚îÇ   ‚îî‚îÄ‚îÄ api/                          # –ö–µ—à API
‚îÇ
‚îú‚îÄ‚îÄ config/                           # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îÇ   ‚îî‚îÄ‚îÄ logging.conf
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml                # Docker Compose
‚îú‚îÄ‚îÄ Dockerfile                        # Dockerfile –¥–ª—è Airflow
‚îú‚îÄ‚îÄ requirements.txt                  # Python –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è Dockerfile
‚îú‚îÄ‚îÄ .env.example                      # –ü—Ä–∏–º–µ—Ä –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
‚îú‚îÄ‚îÄ .gitignore                        # Git ignore
‚îî‚îÄ‚îÄ README.md                         # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
```

---

## –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

- Python 3.10+
- Apache Airflow 2.10+
- PostgreSQL / MongoDB
- Docker & Docker Compose
- pandas, psycopg2, pymongo

–û–ø–∏—à–∏—Ç–µ –ø–æ—Ç–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö, —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∑–∞–¥–∞—á.

---

## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å

### –®–∞–≥ 1: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è

1. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Ñ–∞–π–ª —Å –ø—Ä–∏–º–µ—Ä–æ–º:

    ```bash
    cp .env.example .env
    ```

2. –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ `.env` –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ **–í–°–ï** –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ:

    ```env
    # PostgreSQL Source
    POSTGRES_SOURCE_HOST=postgres-source
    POSTGRES_SOURCE_PORT=5433
    POSTGRES_SOURCE_DB=source_db
    POSTGRES_SOURCE_USER=source_user
    POSTGRES_SOURCE_PASSWORD=source_password

    # PostgreSQL Analytics
    POSTGRES_ANALYTICS_HOST=postgres-analytics
    POSTGRES_ANALYTICS_PORT=5434
    POSTGRES_ANALYTICS_DB=analytics_db
    POSTGRES_ANALYTICS_USER=analytics_user
    POSTGRES_ANALYTICS_PASSWORD=analytics_password

    # MongoDB
    MONGO_HOST=mongodb
    MONGO_PORT=27017
    MONGO_DB=source_mongo_db
    MONGO_USER=mongo_user
    MONGO_PASSWORD=mongo_password

    # ... –∏ —Ç.–¥.
    ```

**–í–ê–ñ–ù–û:**

- –ù–ï –∫–æ–º–º–∏—Ç–∏—Ç—å `.env` –≤ Git
- –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ `.env` –≤ `.gitignore`

### –®–∞–≥ 2: –ó–∞–ø—É—Å–∫ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤

```bash
# –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
docker compose up -d

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
docker compose ps

# –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤
docker compose logs -f airflow
```

**–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã:**

- Airflow web-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å: http://localhost:8080 (admin / admin)
- PostgreSQL Source: localhost:5433
- PostgreSQL Analytics: localhost:5434
- PgAdmin4: http://localhost:5000
- MongoDB: localhost:27017
- Grafana: http://localhost:3000 (admin / admin)

### –®–∞–≥ 3: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö

–ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ —á–µ—Ä–µ–∑ —Å–∫—Ä–∏–ø—Ç—ã –≤ `init/`:

- `init_source_db.sql` - —Å–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—ã orders, customers
- `init_analytics_db.sql` - —Å–æ–∑–¥–∞–µ—Ç daily_business_analytics
- `init_dwh.sql` - —Å–æ–∑–¥–∞–µ—Ç DWH —Å SCD Type 2

### –®–∞–≥ 4: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Airflow Connections

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:**

```bash
docker compose exec -i airflow python /opt/airflow/scripts/setup_connections.py
```

**–í—Ä—É—á–Ω—É—é —á–µ—Ä–µ–∑ UI:**

1. –û—Ç–∫—Ä–æ–π—Ç–µ http://localhost:8080
2. Admin ‚Üí Connections
3. –î–æ–±–∞–≤—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è:

    **postgres_source:**
    - Conn Id: `postgres_source`
    - Conn Type: `Postgres`
    - Host: `postgres-source`
    - Schema: `source_db`
    - Login: `source_user`
    - Password: `<–∏–∑ .env>`
    - Port: `5432`

    **mongodb_conn:**
    - Conn Id: `mongodb_conn`
    - Conn Type: `MongoDB`
    - Host: `mongodb`
    - Schema: `feedback_db`
    - Login: `mongo_user`
    - Password: `<–∏–∑ .env>`
    - Port: `27017`

    **–¥—Ä—É–≥–∏–µ (–ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)**

### –®–∞–≥ 5: –ó–∞–ø—É—Å–∫ DAG

1. –û—Ç–∫—Ä–æ–π—Ç–µ Airflow UI: http://localhost:8080
2. –ù–∞–π–¥–∏—Ç–µ DAG `main_etl_pipeline`
3. –í–∫–ª—é—á–∏—Ç–µ DAG (toggle –≤ –ø–æ–∑–∏—Ü–∏—é ON)
4. –ù–∞–∂–º–∏—Ç–µ `"Trigger DAG"` –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞

DAG –±—É–¥–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞—Ç—å—Å—è –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 9:00 AM.

---

## ETL Pipeline - –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ

### –§–∞–∑–∞ 1: EXTRACT (–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ)

#### 1.1 PostgreSQL

**–¢–∞–±–ª–∏—Ü—ã:**

```sql
-- orders: –∑–∞–∫–∞–∑—ã —Å –¥–∞—Ç–æ–π, —Å—É–º–º–æ–π, —Å—Ç–∞—Ç—É—Å–æ–º
-- customers: –∫–ª–∏–µ–Ω—Ç—ã —Å –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏ –∏ –∞–¥—Ä–µ—Å–∞–º–∏
-- order_items: –ø–æ–∑–∏—Ü–∏–∏ –≤ –∑–∞–∫–∞–∑–∞—Ö —Å —Ç–æ–≤–∞—Ä–∞–º–∏
```

**–°—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è:**

```python
# –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –ø–æ –¥–∞—Ç–µ
extractor = PostgresExtractor(conn_id='postgres_source')

orders_df = extractor.extract_incremental(
    table_name='orders',
    date_column='order_date',
    start_date='{{ ds }}',  # Airflow macro: execution date
    end_date='{{ tomorrow_ds }}'  # –°–ª–µ–¥—É—é—â–∏–π –¥–µ–Ω—å
)
```

**–ü–æ—á–µ–º—É –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞?**

- –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
- –≠–∫–æ–Ω–æ–º–∏–º —Ä–µ—Å—É—Ä—Å—ã
- –ë—ã—Å—Ç—Ä–µ–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è

#### 1.2 MongoDB

**–ö–æ–ª–ª–µ–∫—Ü–∏—è: customer_feedback**

```json
{
  "_id": "ObjectId(...)",
  "customer_id": 123,
  "order_id": 456,
  "rating": 4.5,
  "comment": "–û—Ç–ª–∏—á–Ω—ã–π —Å–µ—Ä–≤–∏—Å!",
  "feedback_date": "2025-01-13T14:30:00Z",
  "category": "delivery"
}
```

**–°—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è:**

```python
extractor = MongoExtractor(
    conn_id='mongodb_conn',
    database='feedback_db'
)

feedback_df = extractor.extract_by_date(
    collection='customer_feedback',
    date_field='feedback_date',
    start_date=execution_date,
    end_date=execution_date + timedelta(days=1)
)
```

#### 1.3 CSV

**–§–∞–π–ª: products_YYYYMMDD.csv**

```csv
product_id,product_name,category,price,stock_quantity
1,Laptop Dell,Electronics,1299.99,50
2,iPhone 15,Electronics,1199.99,120
```

**–°—Ç—Ä–∞—Ç–µ–≥–∏—è:**

```python
extractor = CSVExtractor(base_path='/opt/airflow/data/csv')

products_df = extractor.extract(
    filename=f'products_{execution_date.strftime("%Y%m%d")}.csv'
)
```

#### 1.4 FTP

**–§–∞–π–ª: delivery_logs_YYYYMMDD.csv**

```csv
delivery_id,order_id,courier_id,pickup_time,delivery_time,status
1,1001,25,2025-01-13 09:00:00,2025-01-13 10:30:00,delivered
```

### –§–∞–∑–∞ 2: TRANSFORM (–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è)

#### 2.1 –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö (Data Cleaning)

**–ó–∞–¥–∞—á–∏:**

- –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
- –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
- –£–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤

<details>

**<summary>–ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞ CLEAN</summary>**

```python
class DataCleaner(BaseTransformer):
    def transform(self, df: pd.DataFrame) -> pd.DataFrame:
        # –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        df = df.drop_duplicates(subset=['order_id'], keep='last')
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ null –∑–Ω–∞—á–µ–Ω–∏–π
        df['phone'] = df['phone'].fillna('Unknown')
        df['shipping_address'] = df['shipping_address'].fillna('N/A')
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        df = df[df['total_amount'] > 0]
        df = df[df['quantity'] > 0]
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ (—Å—É–º–º–∞ –∑–∞–∫–∞–∑–∞ > 1 –º–ª–Ω - –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ)
        df = df[df['total_amount'] < 1000000]
        
        return df
```

</details>

#### 2.2 –í–∞–ª–∏–¥–∞—Ü–∏—è (Data Validation)

**–ó–∞–¥–∞—á–∏:**

- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–µ–º—ã –¥–∞–Ω–Ω—ã—Ö
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ –∑–Ω–∞—á–µ–Ω–∏–π
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–æ–≤

<details>

**<summary>–ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞ VALIDATION</summary>**

```python
class DataValidator:
    def validate_orders(self, df: pd.DataFrame) -> tuple:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (valid_df, invalid_df, errors)"""
        errors = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        required_fields = ['order_id', 'customer_id', 'total_amount']
        for field in required_fields:
            if field not in df.columns:
                errors.append(f"Missing required field: {field}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤
        if not pd.api.types.is_numeric_dtype(df['total_amount']):
            errors.append("total_amount must be numeric")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
        invalid_amount = df[
            (df['total_amount'] < 0) | (df['total_amount'] > 1000000)
        ]
        if len(invalid_amount) > 0:
            errors.append(f"Found {len(invalid_amount)} records with invalid amount")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–æ–≤
        valid_statuses = ['pending', 'processing', 'shipped', 'delivered', 'cancelled']
        invalid_status = df[~df['status'].isin(valid_statuses)]
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –≤–∞–ª–∏–¥–Ω—ã–µ –∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ
        valid_mask = (
            df['total_amount'].between(0, 1000000) &
            df['status'].isin(valid_statuses)
        )
        
        valid_df = df[valid_mask]
        invalid_df = df[~valid_mask]
        
        return valid_df, invalid_df, errors
```

</details>

#### 2.3 –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (Data Normalization)

**–ó–∞–¥–∞—á–∏:**

- –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
- –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –¥–∞—Ç
- –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä–æ–∫
- –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π

<details>

**<summary>–ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞ NORMALIZAION</summary>**


```python
class DataNormalizer(BaseTransformer):
    def transform(self, df: pd.DataFrame) -> pd.DataFrame:
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä–æ–∫
        df['country'] = df['country'].str.upper().str.strip()
        df['city'] = df['city'].str.title().str.strip()
        df['email'] = df['email'].str.lower().str.strip()
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤ (—É–±—Ä–∞—Ç—å –≤—Å–µ –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä)
        df['phone'] = df['phone'].str.replace(r'\D', '', regex=True)
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –¥–∞—Ç
        df['order_date'] = pd.to_datetime(df['order_date'])
        df['order_date'] = df['order_date'].dt.tz_localize(None)
        
        # –û–∫—Ä—É–≥–ª–µ–Ω–∏–µ —Ü–µ–Ω
        df['total_amount'] = df['total_amount'].round(2)
        
        return df
```

</details>

#### 2.4 –û–±–æ–≥–∞—â–µ–Ω–∏–µ (Data Enrichment)

**–ó–∞–¥–∞—á–∏:**

- –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª—è–µ–º—ã—Ö –ø–æ–ª–µ–π
- –û–±–æ–≥–∞—â–µ–Ω–∏–µ –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤
- –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è
- –ê–≥—Ä–µ–≥–∞—Ü–∏–∏

<details>

**<summary>–ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞ ENRICH</summary>**

```python
class DataEnricher(BaseTransformer):
    def transform(self, df: pd.DataFrame, products_df: pd.DataFrame = None) -> pd.DataFrame:
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        df['order_hour'] = df['order_date'].dt.hour
        df['order_day_of_week'] = df['order_date'].dt.dayofweek
        df['is_weekend'] = df['order_day_of_week'].isin([5, 6])
        df['time_of_day'] = pd.cut(
            df['order_hour'],
            bins=[0, 6, 12, 18, 24],
            labels=['Night', 'Morning', 'Afternoon', 'Evening']
        )
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø–æ —Å—É–º–º–µ –∑–∞–∫–∞–∑–∞
        df['order_category'] = pd.cut(
            df['total_amount'],
            bins=[0, 1000, 5000, 10000, float('inf')],
            labels=['Small', 'Medium', 'Large', 'VIP']
        )
        
        # –û–±–æ–≥–∞—â–µ–Ω–∏–µ –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ –ø—Ä–æ–¥—É–∫—Ç–æ–≤
        if products_df is not None:
            df = df.merge(
                products_df[['product_id', 'category', 'price']],
                on='product_id',
                how='left'
            )
        
        # –†–∞—Å—á–µ—Ç —Å–∫–∏–¥–∫–∏
        df['discount'] = (df['original_price'] - df['final_price']) / df['original_price']
        df['discount_pct'] = (df['discount'] * 100).round(2)
        
        return df
```

</details>

#### 2.5 –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (Data Quality Assessment)

**–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:**

<details>

**<summary>–ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞ DATA_QUALITY</summary>**

```python
def assess_data_quality(df: pd.DataFrame) -> dict:
    """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö."""
    
    total_records = len(df)
    
    quality_metrics = {
        'total_records': total_records,
        
        # Completeness (–ø–æ–ª–Ω–æ—Ç–∞)
        'completeness': {
            field: (df[field].notna().sum() / total_records * 100)
            for field in df.columns
        },
        
        # Uniqueness (—É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å)
        'uniqueness': {
            'order_id': (df['order_id'].nunique() / total_records * 100),
            'customer_id': (df['customer_id'].nunique() / total_records * 100)
        },
        
        # Validity (–≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å)
        'validity': {
            'valid_emails': (df['email'].str.match(r'^[\w\.-]+@[\w\.-]+\.\w+$').sum() / total_records * 100),
            'valid_amounts': ((df['total_amount'] > 0).sum() / total_records * 100)
        },
        
        # Consistency (–∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å)
        'duplicates': df.duplicated(subset=['order_id']).sum(),
        'null_values': df.isnull().sum().to_dict()
    }
    
    return quality_metrics
```

</details>

### –§–∞–∑–∞ 3: LOAD (–ó–∞–≥—Ä—É–∑–∫–∞)

#### 3.1 –ó–∞–≥—Ä—É–∑–∫–∞ –≤ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫—É—é –ë–î

**–¢–∞–±–ª–∏—Ü–∞: daily_business_analytics**

–≠—Ç–∞ —Ç–∞–±–ª–∏—Ü–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –ê–ì–†–ï–ì–ò–†–û–í–ê–ù–ù–´–ï –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ –¥–µ–Ω—å.

**–°—Ç—Ä–∞—Ç–µ–≥–∏—è: UPSERT**

<details>

**<summary>–ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞ LOAD-UPSERT</summary>**

```python
def load_daily_analytics(df: pd.DataFrame, execution_date: date):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–Ω–µ–≤–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫."""
    
    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –∑–∞ –¥–µ–Ω—å
    analytics = {
        'analytics_date': execution_date,
        'total_orders': len(df),
        'total_revenue': df['total_amount'].sum(),
        'avg_order_value': df['total_amount'].mean(),
        
        # –ü–æ —Å—Ç–∞—Ç—É—Å–∞–º
        'orders_pending': len(df[df['status'] == 'pending']),
        'orders_processing': len(df[df['status'] == 'processing']),
        'orders_delivered': len(df[df['status'] == 'delivered']),
        
        # –ö–ª–∏–µ–Ω—Ç—ã
        'unique_customers': df['customer_id'].nunique(),
        'new_customers': calculate_new_customers(df, execution_date),
        
        # –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –∏–∑ feedback
        'avg_customer_rating': calculate_avg_rating(execution_date)
    }
    
    # UPSERT (INSERT ... ON CONFLICT UPDATE)
    query = """
    INSERT INTO daily_business_analytics (
        analytics_date, total_orders, total_revenue, avg_order_value,
        orders_pending, orders_processing, orders_delivered,
        unique_customers, new_customers, avg_customer_rating
    )
    VALUES (
        %(analytics_date)s, %(total_orders)s, %(total_revenue)s, %(avg_order_value)s,
        %(orders_pending)s, %(orders_processing)s, %(orders_delivered)s,
        %(unique_customers)s, %(new_customers)s, %(avg_customer_rating)s
    )
    ON CONFLICT (analytics_date) DO UPDATE SET
        total_orders = EXCLUDED.total_orders,
        total_revenue = EXCLUDED.total_revenue,
        avg_order_value = EXCLUDED.avg_order_value,
        orders_pending = EXCLUDED.orders_pending,
        orders_processing = EXCLUDED.orders_processing,
        orders_delivered = EXCLUDED.orders_delivered,
        unique_customers = EXCLUDED.unique_customers,
        new_customers = EXCLUDED.new_customers,
        avg_customer_rating = EXCLUDED.avg_customer_rating,
        updated_at = CURRENT_TIMESTAMP
    """
    
    cursor.execute(query, analytics)
    conn.commit()
```

</details>

#### 3.2 –ó–∞–≥—Ä—É–∑–∫–∞ –≤ Data Warehouse —Å SCD Type 2

_–°–∞–º–∞—è –≤–∞–∂–Ω–∞—è –∏ —Å–ª–æ–∂–Ω–∞—è —á–∞—Å—Ç—å –ø—Ä–æ–µ–∫—Ç–∞!_

##### –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è dim_customers (SCD Type 2)

<details>

**<summary>–ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞</summary>**

```python
def load_dim_customers_scd2(customers_df: pd.DataFrame, effective_date: date):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å SCD Type 2.
    
    –õ–æ–≥–∏–∫–∞:
    1. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ –ø–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –≤–µ—Ä—Å–∏—é (is_current=TRUE)
    2. –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
    3. –ï—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å - –∑–∞–∫—Ä—ã–≤–∞–µ–º —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é –∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
    4. –ï—Å–ª–∏ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å - –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
    5. –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –Ω–æ–≤—ã–π - —Å–æ–∑–¥–∞–µ–º –ø–µ—Ä–≤—É—é –≤–µ—Ä—Å–∏—é
    """
    tracked_attributes = ['city', 'country', 'email', 'phone']
    
    for _, customer in customers_df.iterrows():
        customer_id = customer['customer_id']
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏
        current_version = get_current_customer_version(customer_id)
        
        if current_version is None:
            # –ù–û–í–´–ô –ö–õ–ò–ï–ù–¢ - —Å–æ–∑–¥–∞–µ–º –ø–µ—Ä–≤—É—é –≤–µ—Ä—Å–∏—é
            insert_customer_version(
                customer_id=customer_id,
                attributes=customer,
                effective_date=effective_date,
                expiration_date=date(9999, 12, 31),
                is_current=True
            )
            logger.info(f"Inserted NEW customer: {customer_id}")
            
        else:
            # –°–£–©–ï–°–¢–í–£–Æ–©–ò–ô –ö–õ–ò–ï–ù–¢ - –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
            attributes_changed = False
            
            for attr in tracked_attributes:
                if str(current_version[attr]) != str(customer[attr]):
                    attributes_changed = True
                    logger.info(
                        f"Customer {customer_id}: {attr} changed "
                        f"from '{current_version[attr]}' to '{customer[attr]}'"
                    )
                    break
            
            if attributes_changed:
                # –ò–ó–ú–ï–ù–ï–ù–ò–Ø –ï–°–¢–¨ - –ø—Ä–∏–º–µ–Ω—è–µ–º SCD Type 2
                
                # 1. –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ç–µ–∫—É—â—É—é –≤–µ—Ä—Å–∏—é
                close_customer_version(
                    customer_key=current_version['customer_key'],
                    expiration_date=effective_date - timedelta(days=1)
                )
                
                # 2. –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é
                insert_customer_version(
                    customer_id=customer_id,
                    attributes=customer,
                    effective_date=effective_date,
                    expiration_date=date(9999, 12, 31),
                    is_current=True
                )
                
                logger.info(f"Applied SCD Type 2 for customer: {customer_id}")
            else:
                # –ù–ï–¢ –ò–ó–ú–ï–ù–ï–ù–ò–ô - –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
                logger.debug(f"No changes for customer: {customer_id}")

def get_current_customer_version(customer_id: int) -> dict:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π –∞–∫—Ç–∏–≤–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞."""
    query = """
    SELECT *
    FROM dim_customers
    WHERE customer_id = %s AND is_current = TRUE
    LIMIT 1
    """
    cursor.execute(query, (customer_id,))
    row = cursor.fetchone()
    
    if row:
        columns = [desc[0] for desc in cursor.description]
        return dict(zip(columns, row))
    return None

def close_customer_version(customer_key: int, expiration_date: date):
    """–ó–∞–∫—Ä—ã—Ç–∏–µ —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞."""
    query = """
    UPDATE dim_customers
    SET 
        expiration_date = %s,
        is_current = FALSE,
        updated_at = CURRENT_TIMESTAMP
    WHERE customer_key = %s
    """
    cursor.execute(query, (expiration_date, customer_key))

def insert_customer_version(
    customer_id: int,
    attributes: dict,
    effective_date: date,
    expiration_date: date,
    is_current: bool
):
    """–í—Å—Ç–∞–≤–∫–∞ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞."""
    query = """
    INSERT INTO dim_customers (
        customer_id, first_name, last_name, email, phone,
        city, country, customer_segment,
        effective_date, expiration_date, is_current
    )
    VALUES (
        %(customer_id)s, %(first_name)s, %(last_name)s, %(email)s, %(phone)s,
        %(city)s, %(country)s, %(customer_segment)s,
        %(effective_date)s, %(expiration_date)s, %(is_current)s
    )
    """
    
    params = {
        'customer_id': customer_id,
        'first_name': attributes['first_name'],
        'last_name': attributes['last_name'],
        'email': attributes['email'],
        'phone': attributes['phone'],
        'city': attributes['city'],
        'country': attributes['country'],
        'customer_segment': attributes.get('customer_segment', 'Regular'),
        'effective_date': effective_date,
        'expiration_date': expiration_date,
        'is_current': is_current
    }
    
    cursor.execute(query, params)
```

</details>

##### –®–∞–≥ 2: –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–∫—Ç–æ–≤ fact_orders

**–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:** –ü—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–∫—Ç–æ–≤ –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π surrogate key –∏–∑–º–µ—Ä–µ–Ω–∏—è –¥–ª—è –î–ê–¢–´ –ó–ê–ö–ê–ó–ê.

<details>

**<summary>–ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞</summary>**

```python
def load_fact_orders(orders_df: pd.DataFrame):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–∫—Ç–æ–≤ –∑–∞–∫–∞–∑–æ–≤.
    –í–∞–∂–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ–º customer_key –∫–æ—Ç–æ—Ä—ã–π –±—ã–ª –∞–∫—Ç–∏–≤–µ–Ω –Ω–∞ –¥–∞—Ç—É –∑–∞–∫–∞–∑–∞!
    """
    for _, order in orders_df.iterrows():
        order_date = order['order_date'].date()
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ customer_key –¥–ª—è –î–ê–¢–´ –ó–ê–ö–ê–ó–ê
        customer_key = get_customer_key_for_date(
            customer_id=order['customer_id'],
            as_of_date=order_date
        )
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ product_key –¥–ª—è –î–ê–¢–´ –ó–ê–ö–ê–ó–ê
        product_key = get_product_key_for_date(
            product_id=order['product_id'],
            as_of_date=order_date
        )
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ date_key
        date_key = int(order_date.strftime('%Y%m%d'))
        
        # –í—Å—Ç–∞–≤–∫–∞ —Ñ–∞–∫—Ç–∞
        insert_fact_order(
            order_id=order['order_id'],
            customer_key=customer_key,
            product_key=product_key,
            date_key=date_key,
            quantity=order['quantity'],
            unit_price=order['unit_price'],
            total_amount=order['total_amount'],
            order_status=order['status']
        )

def get_customer_key_for_date(customer_id: int, as_of_date: date) -> int:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ customer_key –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –¥–∞—Ç—ã.    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ—Ç customer_key, –∫–æ—Ç–æ—Ä—ã–π –±—ã–ª –∞–∫—Ç–∏–≤–µ–Ω –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∞—Ç—É.
    –≠—Ç–æ –ö–õ–Æ–ß–ï–í–ê–Ø —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã SCD Type 2!
    """
    query = """
    SELECT customer_key
    FROM dim_customers
    WHERE customer_id = %s
      AND effective_date <= %s
      AND expiration_date >= %s
    LIMIT 1
    """
    cursor.execute(query, (customer_id, as_of_date, as_of_date))
    result = cursor.fetchone()
    if result:
        return result[0]
    else:
        logger.error(
            f"No customer_key found for customer_id={customer_id} on {as_of_date}"
        )
        raise ValueError(f"Customer key not found")
```

</details>

**–ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã SCD Type 2 –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–∫—Ç–æ–≤:**

```text
–°–∏—Ç—É–∞—Ü–∏—è:
- –ö–ª–∏–µ–Ω—Ç ID=123 —Å–¥–µ–ª–∞–ª –∑–∞–∫–∞–∑ 01.06.2025
- –ö–ª–∏–µ–Ω—Ç –ø–µ—Ä–µ–µ—Ö–∞–ª 15.06.2025
- –ö–ª–∏–µ–Ω—Ç —Å–¥–µ–ª–∞–ª –µ—â–µ –æ–¥–∏–Ω –∑–∞–∫–∞–∑ 20.06.2025

dim_customers:
customer_key | customer_id | city   | effective_date | expiration_date | is_current
1001         | 123         | –ú–æ—Å–∫–≤–∞ | 2025-01-01     | 2025-06-14      | FALSE
1125         | 123         | –°–ü–±    | 2025-06-15     | 9999-12-31      | TRUE

fact_orders:
fact_id | order_id | customer_key | order_date | ...
100     | 5001     | 1001         | 2025-06-01 | ...  ‚Üê –ü—Ä–∏–≤—è–∑–∞–Ω –∫ –ú–æ—Å–∫–≤–µ
101     | 5002     | 1125         | 2025-06-20 | ...  ‚Üê –ü—Ä–∏–≤—è–∑–∞–Ω –∫ –°–ü–±

–†–µ–∑—É–ª—å—Ç–∞—Ç:
- –ü–µ—Ä–≤—ã–π –∑–∞–∫–∞–∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –∫–ª–∏–µ–Ω—Ç –±—ã–ª –∏–∑ –ú–æ—Å–∫–≤—ã
- –í—Ç–æ—Ä–æ–π –∑–∞–∫–∞–∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –∫–ª–∏–µ–Ω—Ç —É–∂–µ –∏–∑ –°–ü–±
- –ò—Å—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!
```

---


## üìà Data Warehouse - –°—Ö–µ–º–∞ "–ó–≤–µ–∑–¥–∞"

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   dim_date   ‚îÇ
                    ‚îÇ  (dimension) ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇdim_customers ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ dim_products ‚îÇ
       ‚îÇ(SCD Type 2)  ‚îÇ    ‚îÇ    ‚îÇ (SCD Type 2) ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ            ‚îÇ           ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ fact_orders  ‚îÇ
                    ‚îÇ    (fact)    ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### –¢–∞–±–ª–∏—Ü—ã —Ñ–∞–∫—Ç–æ–≤ (Fact Tables)

**fact_orders** - —Ñ–∞–∫—Ç—ã –∑–∞–∫–∞–∑–æ–≤

```sql
CREATE TABLE fact_orders (
    fact_id BIGSERIAL PRIMARY KEY,
    order_id INTEGER NOT NULL,
    
    -- –°—Å—ã–ª–∫–∏ –Ω–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è (SCD Type 2!)
    customer_key INTEGER REFERENCES dim_customers(customer_key),
    product_key INTEGER REFERENCES dim_products(product_key),
    date_key INTEGER REFERENCES dim_date(date_key),
    time_key INTEGER REFERENCES dim_time(time_key),
    
    -- –ú–µ—Ç—Ä–∏–∫–∏ (–≤—Å–µ–≥–¥–∞ —á–∏—Å–ª–æ–≤—ã–µ, –∞–¥–¥–∏—Ç–∏–≤–Ω—ã–µ)
    quantity INTEGER,
    unit_price DECIMAL(10, 2),
    total_amount DECIMAL(12, 2),
    
    -- –î–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–º–µ—Ä–µ–Ω–∏—è
    order_status VARCHAR(50),
    payment_method VARCHAR(50),
    
    loaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### –¢–∞–±–ª–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏–π (Dimension Tables)

**dim_customers** (SCD Type 2)

```sql
CREATE TABLE dim_customers (
    customer_key SERIAL PRIMARY KEY,        -- Surrogate key
    customer_id INTEGER NOT NULL,           -- Natural key
    
    -- –ê—Ç—Ä–∏–±—É—Ç—ã –∫–ª–∏–µ–Ω—Ç–∞
    first_name VARCHAR(100),
    last_name VARCHAR(100),
    email VARCHAR(255),
    phone VARCHAR(20),
    city VARCHAR(100),
    country VARCHAR(100),
    customer_segment VARCHAR(50),
    
    -- SCD Type 2 –ø–æ–ª—è
    effective_date DATE NOT NULL,           -- –î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –¥–µ–π—Å—Ç–≤–∏—è
    expiration_date DATE DEFAULT '9999-12-31',  -- –î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è
    is_current BOOLEAN DEFAULT TRUE,        -- –§–ª–∞–≥ —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
CREATE INDEX idx_dim_customers_current 
    ON dim_customers(customer_id, is_current);
CREATE INDEX idx_dim_customers_dates 
    ON dim_customers(effective_date, expiration_date);
```

**dim_date** (—Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ)

```sql
CREATE TABLE dim_date (
    date_key INTEGER PRIMARY KEY,           -- YYYYMMDD
    full_date DATE NOT NULL UNIQUE,
    day_of_week INTEGER,
    day_name VARCHAR(10),
    month INTEGER,
    month_name VARCHAR(10),
    quarter INTEGER,
    year INTEGER,
    is_weekend BOOLEAN,
    is_holiday BOOLEAN
);
```

### –ó–∞–ø—Ä–æ—Å—ã –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏

**–ü—Ä–∏–º–µ—Ä 1: –í—ã—Ä—É—á–∫–∞ –ø–æ –∫–ª–∏–µ–Ω—Ç–∞–º —Å —É—á–µ—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏**

```sql
-- –í—ã—Ä—É—á–∫–∞ –ø–æ –≥–æ—Ä–æ–¥–∞–º, –≥–¥–µ –∂–∏–ª–∏ –∫–ª–∏–µ–Ω—Ç—ã –Ω–∞ –º–æ–º–µ–Ω—Ç –∑–∞–∫–∞–∑–∞
SELECT 
    c.city,
    COUNT(DISTINCT f.order_id) as total_orders,
    SUM(f.total_amount) as total_revenue,
    AVG(f.total_amount) as avg_order_value
FROM fact_orders f
JOIN dim_customers c ON f.customer_key = c.customer_key
JOIN dim_date d ON f.date_key = d.date_key
WHERE d.year = 2025
GROUP BY c.city
ORDER BY total_revenue DESC;
```

**–ü—Ä–∏–º–µ—Ä 2: –ê–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –∫–ª–∏–µ–Ω—Ç–æ–≤**

```sql
-- –ö–ª–∏–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–µ–Ω—è–ª–∏ –≥–æ—Ä–æ–¥
SELECT 
    customer_id,
    city,
    effective_date,
    expiration_date,
    is_current,
    CASE 
        WHEN is_current = FALSE THEN 'Historical'
        ELSE 'Current'
    END as version_status
FROM dim_customers
WHERE customer_id IN (
    SELECT customer_id
    FROM dim_customers
    GROUP BY customer_id
    HAVING COUNT(*) > 1
)
ORDER BY customer_id, effective_date;
```

---

## –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è - Dashboard –≤ Grafana

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Grafana

1. –û—Ç–∫—Ä–æ–π—Ç–µ Grafana: http://localhost:3000
2. –õ–æ–≥–∏–Ω: admin / admin
3. Add data source ‚Üí PostgreSQL
4. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ `postgres-analytics`

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –ø–∞–Ω–µ–ª–∏ –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞

**1. –û–±–∑–æ—Ä –ø—Ä–æ–¥–∞–∂ (Sales Overview)**

- Total Orders (–æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤)
- Total Revenue (–æ–±—â–∞—è –≤—ã—Ä—É—á–∫–∞)
- Average Order Value (—Å—Ä–µ–¥–Ω–∏–π —á–µ–∫)
- Revenue Trend (—Ç—Ä–µ–Ω–¥ –≤—ã—Ä—É—á–∫–∏ –ø–æ –¥–Ω—è–º)

**SQL –¥–ª—è Total Revenue:**

```sql
SELECT 
    SUM(total_revenue) as total_revenue
FROM daily_business_analytics
WHERE analytics_date >= NOW() - INTERVAL '30 days';
```

**2. –ì–µ–æ–≥—Ä–∞—Ñ–∏—è –ø—Ä–æ–¥–∞–∂ (Sales by Geography)**

- Map: –ø—Ä–æ–¥–∞–∂–∏ –ø–æ –≥–æ—Ä–æ–¥–∞–º
- Top 10 Cities (—Ç–æ–ø-10 –≥–æ—Ä–æ–¥–æ–≤ –ø–æ –≤—ã—Ä—É—á–∫–µ)
- Orders by Country (–∑–∞–∫–∞–∑—ã –ø–æ —Å—Ç—Ä–∞–Ω–∞–º)

**SQL –¥–ª—è —Ç–æ–ø-10 –≥–æ—Ä–æ–¥–æ–≤:**

```sql
SELECT 
    c.city,
    COUNT(DISTINCT f.order_id) as orders,
    SUM(f.total_amount) as revenue
FROM fact_orders f
JOIN dim_customers c ON f.customer_key = c.customer_key
WHERE c.is_current = TRUE
GROUP BY c.city
ORDER BY revenue DESC
LIMIT 10;
```

**3. –ê–Ω–∞–ª–∏–∑ –∫–ª–∏–µ–Ω—Ç–æ–≤ (Customer Analysis)**

- New vs Returning Customers
- Customer Segments Distribution
- Average Customer Rating
- Top Customers by Revenue

**SQL –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤:**

```sql
SELECT 
    c.customer_segment,
    COUNT(DISTINCT c.customer_id) as customers,
    SUM(f.total_amount) as revenue
FROM fact_orders f
JOIN dim_customers c ON f.customer_key = c.customer_key
GROUP BY c.customer_segment;
```

**4. –ö–∞—á–µ—Å—Ç–≤–æ —Å–µ—Ä–≤–∏—Å–∞ (Service Quality)**

- Average Rating (—Å—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥)
- Rating Distribution (—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫)
- Delivery Success Rate (–ø—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω—ã—Ö –¥–æ—Å—Ç–∞–≤–æ–∫)
- Average Delivery Time (—Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –¥–æ—Å—Ç–∞–≤–∫–∏)

**SQL –¥–ª—è —Ä–µ–π—Ç–∏–Ω–≥–∞:**

```sql
SELECT 
    DATE(analytics_date) as date,
    avg_customer_rating
FROM daily_business_analytics
WHERE analytics_date >= NOW() - INTERVAL '30 days'
ORDER BY date;
```

**5. –¢–æ–≤–∞—Ä—ã (Products)**

- Top 10 Products (—Ç–æ–ø-10 —Ç–æ–≤–∞—Ä–æ–≤)
- Sales by Category (–ø—Ä–æ–¥–∞–∂–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º)
- Low Stock Alert (—Ç–æ–≤–∞—Ä—ã —Å –Ω–∏–∑–∫–∏–º –æ—Å—Ç–∞—Ç–∫–æ–º)

---

## –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–ª–µ—Ä—Ç—ã

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–ª–µ—Ä—Ç–æ–≤ –≤ Airflow

**–í DAG —Ñ–∞–π–ª–µ:**

```python
default_args = {
    'owner': 'student',
    'email': ['student@example.com'],
    'email_on_failure': True,       # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    'email_on_retry': False,         # –ù–µ —É–≤–µ–¥–æ–º–ª—è—Ç—å –ø—Ä–∏ retry
    'email_on_success': False,       # –ù–µ —É–≤–µ–¥–æ–º–ª—è—Ç—å –ø—Ä–∏ —É—Å–ø–µ—Ö–µ
    'retries': 3,
    'retry_delay': timedelta(minutes=5),
}
```

### –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞

**1. –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:**

- –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è DAG
- –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU

**2. –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö:**

- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
- –ü—Ä–æ—Ü–µ–Ω—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
- –ü—Ä–æ—Ü–µ–Ω—Ç null –∑–Ω–∞—á–µ–Ω–∏–π

**3. –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å:**

- –°—Ç–∞—Ç—É—Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π –∫ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
- –ó–∞–¥–µ—Ä–∂–∫–∏ –≤ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–∏

**–ü—Ä–∏–º–µ—Ä –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫:**

```python
def log_data_quality_metrics(**context):
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –≤ –ë–î."""
    execution_date = context['execution_date']
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∏–∑ XCom
    orders_count = context['task_instance'].xcom_pull(
        key='orders_count', 
        task_ids='extract_postgres_orders'
    )
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ data_quality_metrics
    insert_quality_metrics(
        run_date=execution_date,
        dag_id=context['dag'].dag_id,
        task_id=context['task'].task_id,
        source_name='postgres_orders',
        total_records=orders_count,
        # ... –¥—Ä—É–≥–∏–µ –º–µ—Ç—Ä–∏–∫–∏
    )
```

---

## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é

### –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ (1-2 –¥–Ω—è)

1. –í—ã–±–æ—Ä –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏
2. –ü—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
3. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Docker –æ–∫—Ä—É–∂–µ–Ω–∏—è
4. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö

### –≠—Ç–∞–ø 2: –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ Extract (2-3 –¥–Ω—è)

1. –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –∫–ª–∞—Å—Å–æ–≤ Extractors
2. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
3. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö

### –≠—Ç–∞–ø 3: –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ Transform (2-3 –¥–Ω—è)

1. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–æ–≤
2. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
3. –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤
4. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏

### –≠—Ç–∞–ø 4: –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ Load (2-3 –¥–Ω—è)

1. –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã DWH
2. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑—á–∏–∫–æ–≤
3. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏
4. –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö

### –≠—Ç–∞–ø 5: Airflow DAG (2-3 –¥–Ω—è)

1. –°–æ–∑–¥–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ DAG
2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∑–∞–¥–∞—á
3. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞
4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è

### –≠—Ç–∞–ø 6: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (1-2 –¥–Ω—è)

1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Grafana/Metabase
2. –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—à–±–æ—Ä–¥–∞
3. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
4. –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –≠—Ç–∞–ø 7: –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (1-2 –¥–Ω—è)

1. –ù–∞–ø–∏—Å–∞–Ω–∏–µ README
2. –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ API
3. –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏
4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –∑–∞—â–∏—Ç–µ

---

## –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏ –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã

### 1. –ü–æ–ª–Ω–æ—Ç–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ (35 –±–∞–ª–ª–æ–≤)

- –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö 3+ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö (8 –±–∞–ª–ª–æ–≤)
- –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Ä–∞–±–æ—Ç–∞ Extract-Transform-Load (10 –±–∞–ª–ª–æ–≤)
- –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π Data Warehouse —Å **SCD Type 2** (12 –±–∞–ª–ª–æ–≤)
  - –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è (effective_date, expiration_date, is_current)
  - –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π
  - –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏–π –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö
  - –ü—Ä–∏–≤—è–∑–∫–∞ —Ñ–∞–∫—Ç–æ–≤ –∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –≤–µ—Ä—Å–∏—è–º –∏–∑–º–µ—Ä–µ–Ω–∏–π
- –†–∞–±–æ—Ç–∞—é—â–∏–π –¥–∞—à–±–æ—Ä–¥ (5 –±–∞–ª–ª–æ–≤)

### 2. –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è–º–∏ (15 –±–∞–ª–ª–æ–≤)

- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ `.env` —Ñ–∞–π–ª–∞ –¥–ª—è —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (5 –±–∞–ª–ª–æ–≤)
- `.env` –¥–æ–±–∞–≤–ª–µ–Ω –≤ `.gitignore`, –Ω–µ—Ç —Ö–∞—Ä–¥–∫–æ–¥ –ø–∞—Ä–æ–ª–µ–π –≤ –∫–æ–¥–µ (3 –±–∞–ª–ª–∞)
- –ù–∞—Å—Ç—Ä–æ–µ–Ω—ã **Airflow Connections** –¥–ª—è –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (5 –±–∞–ª–ª–æ–≤)
- –ö–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Airflow Hooks (`PostgresHook`, `MongoHook`) (2 –±–∞–ª–ª–∞)

### 3. –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞ (25 –±–∞–ª–ª–æ–≤)

- –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ (10 –±–∞–ª–ª–æ–≤)
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (8 –±–∞–ª–ª–æ–≤)
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (7 –±–∞–ª–ª–æ–≤)

### 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Airflow (15 –±–∞–ª–ª–æ–≤)

- –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ DAG (8 –±–∞–ª–ª–æ–≤)
- –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á (4 –±–∞–ª–ª–∞)
- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–ª–µ—Ä—Ç—ã (3 –±–∞–ª–ª–∞)

### 5. –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (10 –±–∞–ª–ª–æ–≤)

- README —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏ –ø–æ –∑–∞–ø—É—Å–∫—É –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ .env (5 –±–∞–ª–ª–æ–≤)
- –û–ø–∏—Å–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏ —Ä–µ—à–µ–Ω–∏–π, –≤–∫–ª—é—á–∞—è –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è SCD Type 2 (5 –±–∞–ª–ª–æ–≤)

---

## –ü–æ–ª–µ–∑–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

**Apache Airflow:**
- [–û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è Apache Airflow](https://airflow.apache.org/docs/apache-airflow/2.11.0/)
- [Best Practices](https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html)
- [Managing Connections](https://airflow.apache.org/docs/apache-airflow/stable/howto/connection.html)
- [Pandas Documentation](https://pandas.pydata.org/docs/)

**PostgreSQL:**
- [PostgreSQL 15 Documentation](https://www.postgresql.org/docs/15/)
- [PostgreSQL Performance Tips](https://wiki.postgresql.org/wiki/Performance_Optimization)

**MongoDB:**
- [MongoDB Manual](https://docs.mongodb.com/manual/)
- [PyMongo Documentation](https://pymongo.readthedocs.io/)

**Data Warehouse:**
- [Kimball Group - Star Schema](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/)
- [SCD Type 2 Explanation](https://en.wikipedia.org/wiki/Slowly_changing_dimension)

**Grafana:**
- [Grafana Documentation](https://grafana.com/docs/grafana/latest/)
- [PostgreSQL Data Source](https://grafana.com/docs/grafana/latest/datasources/postgres/)

### –ö–Ω–∏–≥–∏

1. **"Data Pipelines with Apache Airflow"** - Bas Harenslak, Julian de Ruiter
   - –õ—É—á—à–∞—è –∫–Ω–∏–≥–∞ –ø–æ Airflow
   - –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã
   - Best practices

2. **"The Data Warehouse Toolkit"** - Ralph Kimball, Margy Ross
   - –ë–∏–±–ª–∏—è –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è DWH
   - –ü–æ–¥—Ä–æ–±–Ω–æ –ø—Ä–æ SCD
   - –°—Ö–µ–º—ã "–∑–≤–µ–∑–¥–∞" –∏ "—Å–Ω–µ–∂–∏–Ω–∫–∞"

3. **"Designing Data-Intensive Applications"** - Martin Kleppmann
   - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ data —Å–∏—Å—Ç–µ–º
   - –ü–∞—Ç—Ç–µ—Ä–Ω—ã –∏ –∞–Ω—Ç–∏-–ø–∞—Ç—Ç–µ—Ä–Ω—ã
   - –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

### –°—Ç–∞—Ç—å–∏ –∏ –±–ª–æ–≥–∏

- [Apache Airflow Blog](https://airflow.apache.org/blog/)
- [Kimball Group Blog](https://www.kimballgroup.com/blog/)
- [dbt Blog - Analytics Engineering](https://blog.getdbt.com/)

### –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

- **DBeaver** - GUI –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ë–î
- **Postman** - —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ API
- **Docker Desktop** - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º–∏
- **VS Code** - IDE —Å –ø–ª–∞–≥–∏–Ω–∞–º–∏ –¥–ª—è Python

---
