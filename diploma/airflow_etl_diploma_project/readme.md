# Дипломная работа: ETL-Pipeline с Apache Airflow

## Тема: "Дашборд аналитика бизнес-процессов"

### Цель проекта

Разработать полноценный ETL-pipeline на базе Apache Airflow 2.11 для автоматизированного сбора, обработки и визуализации данных бизнес-процессов. Система должна ежедневно (в 9:00) собирать данные из различных источников, трансформировать их и загружать в аналитическую БД и Data Warehouse для последующей визуализации.

---

## Ключевые требования

### 1. Data Warehouse с SCD Type 2

Хранилище данных должно использовать стратегию **Slowly Changing Dimensions (SCD) Type 2** для отслеживания исторических изменений. Это позволит:

- Сохранять полную историю изменений атрибутов
- Анализировать данные в контексте их исторического состояния
- Обеспечить аудит изменений данных

### 2. Безопасность подключений

- Все подключения через **Airflow Connections**
- Учетные данные передаются через **переменные окружения (.env файл)**
- Жесткое кодирование паролей в коде **ЗАПРЕЩЕНО**

### 3. Минимум 3 источника данных

- PostgreSQL (транзакционная БД)
- MongoDB (документо-ориентированная БД)
- CSV/FTP (файловые источники)
- REST API (опционально)

---

## Быстрый старт

### 1. Клонирование проекта

```bash
cd airflow_etl_diploma_project
```

### 2. Настройка переменных окружения

Создайте файл `.env` на основе `.env.example`:

```bash
cp .env.example .env
```

Отредактируйте `.env` и заполните все необходимые переменные.

### 3. Запуск Docker контейнеров

```bash
docker compose up -d
```

Сервисы будут доступны по адресам:

- Airflow UI: http://localhost:8080 (admin/admin)
- Grafana: http://localhost:3000
- PostgreSQL Source: localhost:5433
- PostgreSQL Analytics: localhost:5434
- MongoDB: localhost:27017

### 4. Настройка Airflow Connections

```bash
docker compose exec -i airflow python /opt/airflow/scripts/setup_connections.py
```

### 5. Запуск DAG

1. Откройте Airflow UI: http://localhost:8080
2. Включите DAG `main_etl_pipeline`
3. DAG будет автоматически запускаться каждый день в 9:00

---

Полная документация находится в файле [../readme.md](../readme.md).
